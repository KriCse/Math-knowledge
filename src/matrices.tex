\chapter{Matrices}
\section{Properties}
\subsection{Dimension}
The dimension
\footnote{Not to be confused with the dimenson of a vector space, see \ref{dimension}} is the number of rows \(a\) and columns \(b\) of a Matrix \(A\)
\begin{equation}
    \dim{A} = a \times b
\end{equation}
Denoted as:
\begin{align*}
    A^{a \times b}
\end{align*}
\begin{example}
    \begin{equation*}
        \dim{\begin{bmatrix}
                1 & 2 & 3 \\
                4 & 5 & 6
            \end{bmatrix}} = 2 \times 3
    \end{equation*}
\end{example}
\begin{example}[Linearly dependent rows/columns]
    \begin{equation*}
        \dim{\begin{bmatrix}
                1 & 2 \\
                2 & 4
            \end{bmatrix}}= 2 \times 2
    \end{equation*}
\end{example}
\begin{matlab}
    \apilink{size}{https://www.mathworks.com/help/matlab/ref/size.html}
    \begin{lstlisting}
    A = [[1,2,3],[1,2,3]]
    size(A)
    ans 2 3
    \end{lstlisting}
\end{matlab}
\subsection{Rank (Rang)} \label{rank}
\subsubsection{Rowsapce, columnspace}
The rowspace \( C \) of a matrix ist the span of its column vectors. \\
The definied as is the span of its row vectors. It is dentoed as \( C(A^T) \)\\
The dimension of the column and rowspace are always equal.
\begin{example}
    \begin{align*}
        A         & = \begin{bmatrix}
            1 & 2 & 4 \\ 1 & 2 & 4
        \end{bmatrix}      \\
        C(A)      & = \setb{
        \begin{bmatrix}
                c \\ c
            \end{bmatrix}}{c \in \mathbb{R}} \\
        C(A^T)    & = \setb{
        \begin{bmatrix}
                c \\ 2c \\ 4c
            \end{bmatrix}}{c \in \mathbb{R}} \\
        \dim C(A) & = \dim C(A^T) = 1                 \\
    \end{align*}
\end{example}
\subsubsection{Rank}
The rank of a matrix \(A\) is the maximal number of linearly independent columns
(or the number of linearly independent rows, is the same thing). Or equally, the rank
of a matrix A is the dimenson of its columnspace (or rowspace):
\begin{equation}
    \rank A = \dim C(A) = \dim C(A^T)
\end{equation}
\begin{example}
    \begin{equation*}
        \rank \begin{bmatrix}
            1 & 2 & 3 \\
            4 & 5 & 6
        \end{bmatrix} = 2
    \end{equation*}
\end{example}
\begin{example}[Both rows are linearly dependent]
    \begin{equation*}
        \rank \begin{bmatrix}
            1 & 2 & 3 \\
            2 & 4 & 6
        \end{bmatrix}  = 1 \\
    \end{equation*}
\end{example}
\begin{example}[Only a matrix containing zeroes has a rank of 0]
    \begin{equation*}
        \rank \begin{bmatrix}
            0 & 0 & 0 \\
            0 & 0 & 0
        \end{bmatrix} = 0
    \end{equation*}
\end{example}
\begin{example}
    Both columns are linearly independent, some rows are linearly dependent.
    \begin{equation*}
        \rank \begin{bmatrix}
            1 & 2 \\ 2 & 4 \\ 5 & 7
        \end{bmatrix} = 2
    \end{equation*}
\end{example}
\begin{matlab}
    \apilink{rank}{https://www.mathworks.com/help/matlab/ref/rank.html}
    \begin{lstlisting}
    A = [[1,2,3],[1,2,3]]
    rank(A)
    ans = 1
    \end{lstlisting}
\end{matlab}
\subsection{Trace (Spur)}
The trace of a square matrix \( A \) is the sum of all its main diagonal elements.
\begin{equation}
    tr(A) = \sum_{i=0}^{n} a_{ii}
\end{equation}

\begin{example}
    \begin{align*}
        A     & = \begin{bmatrix}
            1 & 2 & 3 \\ 4 & 5 & 6 \\ 7 & 8 & 9
        \end{bmatrix} \\
        tr(A) & = 1 + 5 + 9 = 15
    \end{align*}
\end{example}

\begin{matlab}
    \apilink{trace}{https://www.mathworks.com/help/matlab/ref/double.trace.html}
    \begin{lstlisting}
>> A = [1,2,3;4,5,6;7,8,9]
>> trace(A)
ans =
15
\end{lstlisting}
\end{matlab}
\subsection{Minor, Cofactors}\label{minor}
\subsubsection{Submatrix}
A submatrix \(S_ij\) of a Matrix \(A\) is the Matrix obtained by deleting the \(i\)th Row and deleting the \(j\)th column.
\begin{example}
    \begin{align*}
        A      & = \begin{bmatrix}
            1 & 2 & 3 \\ 4 & 5 & 6 \\ 7 & 8 & 9
        \end{bmatrix} \\
        S_{12} & = \begin{bmatrix}
            4 & 6 \\ 7 & 9
        \end{bmatrix}
    \end{align*}
\end{example}
\subsubsection{Minor}
A minor \(M_{ij}\) of a matrix \(A\) is the determinant of the submatrix \(S_{ij}\).
\subsubsection{Cofactors}
A cofactor \( C_{ij} \) is obtained by multiplying the minor \( M_{ij} \) by \( (-1)^{i + j} \). The cofactor Matrix \(C \) is given by:
\begin{equation}
    C = \begin{bmatrix}
        C_{11} & C_{12} & \dots  & C_{1i} \\
        C_{21} & C_{22} & \dots  & C_{1i} \\
        \vdots & \vdots & \ddots          \\
        C_{j1} & C_{j2} &        & C_{ij} \\
    \end{bmatrix} =  \begin{bmatrix}
        M_{11}            & -M_{12}             & \dots  & (-1)^{i + 1}M_{1i}  \\
        -M_{21}           & M_{22}              & \dots  & (-1)^{i + 2} M_{2i} \\
        \vdots            & \vdots              & \ddots                       \\
        (-1)^{1+ j}M_{j1} & (-1)^{2 + j} M_{j2} &        & (-1)^{i + j} M_{ij} \\
    \end{bmatrix}
\end{equation}
\begin{example}\label{minor_example}
    \begin{align*}
        A = \begin{bmatrix}
            1 & 2 & 3 \\
            4 & 5 & 6 \\
            7 & 8 & 9 \\
        \end{bmatrix} \\
    \end{align*}
    \begin{align*}
        M_{11} & = det(\begin{bmatrix}
            5 & 6 \\
            8 & 9 \\
        \end{bmatrix}) = -3  &
        M_{12} & = det(\begin{bmatrix}
            4 & 6 \\
            7 & 9 \\
        \end{bmatrix}) = -6  &
        M_{13} & = det(\begin{bmatrix}
            4 & 5 \\
            7 & 8 \\
        \end{bmatrix}) = -3    \\
        M_{21} & = det(\begin{bmatrix}
            2 & 3 \\
            8 & 9 \\
        \end{bmatrix}) = -6  &
        M_{22} & = det(\begin{bmatrix}
            1 & 3 \\
            7 & 9 \\
        \end{bmatrix}) = -12 &
        M_{23} & = det(\begin{bmatrix}
            1 & 2 \\
            7 & 8 \\
        \end{bmatrix}) = -6    \\
        M_{31} & = det(\begin{bmatrix}
            2 & 3 \\
            5 & 6 \\
        \end{bmatrix}) = -3  &
        M_{32} & = det(\begin{bmatrix}
            1 & 4 \\
            3 & 6 \\
        \end{bmatrix}) = -6 &
        M_{33} & = det(\begin{bmatrix}
            1 & 2 \\
            4 & 5 \\
        \end{bmatrix}) = -3
    \end{align*}
    \begin{equation*}
        C = \begin{bmatrix}
            M_{11}  & -M_{12} & M_{13}  \\
            -M_{21} & M_{22}  & -M_{23} \\
            M_{31}  & -M_{32} & M_{33}  \\
        \end{bmatrix} = \begin{bmatrix}
            -3 & 6   & -3 \\
            6  & -12 & 6  \\
            -3 & 6   & -3 \\
        \end{bmatrix}
    \end{equation*}
\end{example}
\begin{example}
    \begin{equation*}
        A = \begin{bmatrix}
            1 & 2 \\ 3 & 4
        \end{bmatrix}
    \end{equation*}
    \begin{align*}
        M_{11} & = 4 & M_{12} & = 3 \\
        M_{21} & = 2 & M_{22} & = 1
    \end{align*}
    \begin{equation*}
        C = \begin{bmatrix}
            M_{11}  & -M_{12} \\
            -M_{21} & M_22
        \end{bmatrix} = \begin{bmatrix}
            4 & -3 \\ -2 & 1
        \end{bmatrix}
    \end{equation*}
\end{example}
\subsection{Determinant}
\subsubsection{2x2 Matrix}
For 2x2 Matrix the formula is as given:
\begin{align*}
    \determinant{\begin{bmatrix}
            x_1, x_2 \\
            x_3, x_4 \\
        \end{bmatrix}} = x_1 \cdot x_4 - x_2 \cdot x_4
\end{align*}
\begin{example}
    \begin{align*}
        \determinant{
            \begin{bmatrix}
                3 & 7 \\ -5 & 11
            \end{bmatrix}
        } = 3 \cdot 11 - 7 \cdot (-5) = 68
    \end{align*}
\end{example}
\subsubsection{3x3 Matrix}
The determinant of a 3x3 Matrix can be calculated using its minors.
\begin{align*}
    \determinant{\begin{bmatrix}
            x_1 & x_2 & x_3  \\
            x_4 & x_5 & x_6  \\
            x_7 & x_8 & x_9) \\
        \end{bmatrix}} & = x_1 \cdot
    \determinant{\begin{bmatrix}
            x_5 & x_6 \\
            x_8 & x_9 \\
        \end{bmatrix}}- x_2 \cdot
    \determinant{\begin{bmatrix}
            x_4 & x_6 \\
            x_7 & x_9 \\
        \end{bmatrix}}+ x_3 \cdot \determinant{\begin{bmatrix}
            x_4 & x_5 \\
            x_7 & x_8 \\
        \end{bmatrix}}                                  \\
                                              & = x_1 (x_5x_9 - x_6 x_8) - x_2 (x_4 x_9 - x_6 x_7) + x_3 (x_4 x_8 - x_5 x_7)        \\
                                              & = x_1 x_5 x_9 + x_2 x_6 x_7 + x_3 x_4 x_8 - x_3 x_5 x_7 - x_2 x_4 x_9 - x_1 x_6 x_8
\end{align*}
For higher order matrices you can apply this method recursively.
\begin{example}
    Minors were calculated in previous example.
    \begin{align*}
        \determinant{\begin{bmatrix}
                1 & 2 & 3 \\
                4 & 5 & 6 \\
                7 & 8 & 9 \\
            \end{bmatrix}} & = 1 \cdot(-3) - 2 \cdot(-6) + 3 \cdot(-3) = 0 \\
    \end{align*}
\end{example}
\subsubsection{Triangular matrx}
\begin{align*}
    D = \begin{bmatrix}
        x_{11} & x_{12} & \cdots & x_{1n} \\
        0      & x_{22} &        &        \\
        \vdots &        & \ddots          \\
        0      & 0      & \cdots & x_{nn} \\
    \end{bmatrix} \det(D) & = x_{11} \cdot x_{22} \dots x_{nn} = \prod_{i=1}^n x_{}
\end{align*}
\subsubsection{Singular matrix}
Singular matrices are matrices with \( \det = 0 \).
Singular matrices have rows and/or columns that are not linearly independent.
\begin{example}
    \begin{align*}
        A               & = \begin{bmatrix}
            1 & 2 \\ -2 & -4
        \end{bmatrix}     \\
        \determinant{A} & = 1 \cdot (-4) - (-2) \cdot 2 = 0
    \end{align*}
\end{example}
\begin{matlab}
    \apilink{det}{https://www.mathworks.com/help/matlab/ref/det.html}
    \begin{lstlisting}
>> a =[[3,7];[4,12]]
>> det(a)
ans = 8
\end{lstlisting}
\end{matlab}
\subsection{Eigenvalues, Eigenvectors}\label{eigen}
An eigenvector \( v \) of a square matrix \(A\) is a nonzero vector that changes at most by a scalar factor when that linear transformation is applied to it. The corresponding eigenvalue $\lambda$ is the factor by which the eigenvector is scaled.
\begin{equation} \label{eigenexpression}
    A\cdot v = \lambda \cdot v
\end{equation}
\begin{example}
    \begin{align*}
        A         & = \begin{bmatrix}
            5 & 1 \\ 0 & 3
        \end{bmatrix}                                                                 \\
        v         & = \begin{bmatrix}
            1 \\ 0
        \end{bmatrix}, \lambda = 5                                                    \\
        A \cdot v & = \begin{bmatrix}
            5 & 1 \\ 0 & 3
        \end{bmatrix} \cdot \begin{bmatrix}
            1 \\ 0
        \end{bmatrix} = \begin{bmatrix}
            5 \\ 0
        \end{bmatrix}
    \end{align*}
\end{example}
\subsubsection{Characteristic polynomial}
The expression \ref{eigenexpression} can be written as:
\begin{align}
    A\cdot v = \lambda \cdot I \cdot v \tag*{Multiplying with identity Matrix} \\
    A \cdot v - \lambda \cdot I \cdot v = 0                                    \\
    v \cdot (A - \lambda \cdot I) = 0
\end{align}
Since \(v\) per definition can't be the zero vector, the expression \( (A - \lambda \cdot I) \) must be zero.
\begin{align*}
    A - \lambda \cdot I = 0                 \\
    \determinant{ A - \lambda \cdot I } = 0 \\
    \determinant{
        \begin{bmatrix}
            a_{11} - \lambda & a_{12}           & \cdots & a_{1n}           \\
            a_{12}           & a_{22} - \lambda &        &                  \\
            \vdots           &                  & \ddots &                  \\
            a_{n1}           &                  &        & a_{nn} - \lambda
        \end{bmatrix}
    } & = 0
\end{align*}
The characteristic polynomial \( P_{A}\) of a matrix \(A\) is defined as:
\begin{equation}
    P_A(t) = \determinant{A - t I}
\end{equation}
If a square matrix A with \( \dim(A) = n \times n \) then \(p_A(t)\) will have a degree of \(n\).
\begin{example}\label{eigenexample}
    \begin{align*}
        A      & = \begin{bmatrix}
            5 & 7 \\ 11 & 3
        \end{bmatrix}                                                                   \\
        p_A(t) & = \determinant{\begin{bmatrix}
                5 - t & 7 \\ 11 & 3 -t
            \end{bmatrix}} = (5 - t) \cdot (3 - t) - 7 \cdot 11 = t^2 - 8 - 62
    \end{align*}
\end{example}
\begin{matlab}
    \apilink{charpoly}{https://www.mathworks.com/help/symbolic/sym.charpoly.html}
    \begin{lstlisting}
    >> charpoly([5, 7 ; 11, 3])
    ans =
         1    -8   -62
   \end{lstlisting}
\end{matlab}
\subsubsection{Characteristic equation}
The roots of the characteristic polynomial are the eigenvalues \(\lambda_i \) of \(A\). The expression
\begin{equation}
    p_A(t) = 0\\
\end{equation}
is called the characteristic equation. The characteristic polynomial can be written as:
\begin{equation}
    p_A(t) = (t - \lambda_1)(t - \lambda_2) \cdots (t - \lambda_i)
\end{equation}
\begin{example}\label{eigenexampld}
    \begin{align*}
        A      & = \begin{bmatrix}
            3 & 7 \\ 2 & 5
        \end{bmatrix}                                                 \\                                                                                                                                                  \\
        p_A(t) & = \det(A - t I)  = \determinant{\begin{bmatrix}
                3 - t & 7 \\2  & 5 - t
            \end{bmatrix}} =  t^2 - 8 t + 1 \\
    \end{align*}
    We get the eigenvalues by setting \(p_A(\lambda) = 0\) and solving for \( \lambda \)
    \begin{align*}
        \lambda^2 - 8 \lambda + 1 = 0                                           \\
        \lambda_{12} = -\frac{-8}{2} \pm \sqrt{\left( \frac{-8}{2}\right)^2 -1} \\
        \lambda_1 = 4 - \sqrt{15},  \lambda_2 = 4 + \sqrt{15}                   \\
    \end{align*}
\end{example}
\subsubsection{Arithmetic Multiplity}
A matrix can have multiple eigenvalues $\lambda_i$ with the same value.
The characteristic polynomial can be written as:
\begin{align*}
    p_A(t) = (t-\lambda_1)(t-\lambda_2) \dots (t-\lambda_n)
\end{align*}
The arithmetic Multiplicity $\mu_A(\lambda_1)$ is the number of times $(t - \lambda_i)$ can divide $p_A(t)$,
so the highest power $(t - \lambda_i)$ can have (simply said the number of times a value appears).
\begin{example}
    \begin{align*}
        A = \begin{bmatrix}
            1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
            0 & 2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
            0 & 0 & 3 & 0 & 0 & 0 & 0 & 0 & 0 \\
            0 & 0 & 0 & 3 & 0 & 0 & 0 & 0 & 0 \\
            0 & 0 & 0 & 0 & 3 & 0 & 0 & 0 & 0 \\
            0 & 0 & 0 & 0 & 0 & 4 & 0 & 0 & 0 \\
            0 & 0 & 0 & 0 & 0 & 0 & 4 & 0 & 0 \\
            0 & 0 & 0 & 0 & 0 & 0 & 0 & 4 & 0 \\
            0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 4 \\
        \end{bmatrix}
    \end{align*}
    A has 4 eigenvalues: 1, 2, 3, 4($=\lambda_{1..10})$\\
    The characteristic polynomial can be expressed by using only distinct eigenvalues:
    \begin{align*}
        p_A(t) = (t -1)(t-2)^2(t-3)^3(t-4)^4
    \end{align*}
\end{example}
For example $\mu_A(\lambda_4) = 4$, because $(t - 4)$ divides $p_A(t)$ 4 times.
\subsubsection{Eigenvectors}
To find the eigenvector of an associatited eigenvalue we need to find the kernel of the following linear map:
\begin{align*}
    L:  (A - \lambda_i \cdot I) x = y \\
    \epsilon_i = \ker L
\end{align*}
Since the kernel of a tranformation forms a vectorspace  \( \epsilon \) called \textbf{eigenspace}. So following properites are satisfied:
\begin{align*}
    v_1, v_2 \in \epsilon_i, c \in \mathbb{F} \\
    v_1 + v_2 \in \epsilon_i                  \\
    c \cdot v_1 \in \epsilon                  \\
\end{align*}
\begin{example}
    Continuing  example \ref{eigenexample}.
    \begin{align*}
        A & = \begin{bmatrix}
            3 & 7 \\ 2 & 5
        \end{bmatrix}                     \\                                                                                                                                                  \\
        \lambda_1 = 4 - \sqrt{15},  \lambda_2 = 4 + \sqrt{15} \\
    \end{align*}
    \(\lambda_1\):
    \begin{align*}
        \begin{bmatrix}
            3 - (4 - \sqrt{15}) & 7 \\ 2 & 5 - ( 4 - \sqrt{15})
        \end{bmatrix}
        \begin{bmatrix}
            x_1 \\ x_2
        \end{bmatrix}= \begin{bmatrix}
            0 \\ 0
        \end{bmatrix}                            \\
        \begin{bmatrix}
            -1 + \sqrt{15} & 7 \\ 2 & 1 + \sqrt{15}
        \end{bmatrix}\begin{bmatrix}
            x_1 \\ x_2
        \end{bmatrix}= \begin{bmatrix}
            0 \\ 0
        \end{bmatrix} \\
    \end{align*}
    We can eliminate the II row by subtracting I $ \left( \frac{2}{-1 + \sqrt{15}} \right) $ \\
    \begin{align*}
        \begin{bmatrix}
            -1 + \sqrt{15} & 7 \\ 2 & 1 + \sqrt{15}
        \end{bmatrix} \rightarrow
        \begin{bmatrix}
            -1 + \sqrt{15} & 7 \\ 2 - 2 & (1 + \sqrt{15})-  \left(\frac{14}{-1 + \sqrt{15}} \right)
        \end{bmatrix} = \begin{bmatrix}
            -1 + \sqrt{15} & 7 \\ 0 & 0
        \end{bmatrix}
    \end{align*}
    Since the last row was eliminated, we see that  of $rank(A- \lambda I)$ is 1. It means $x_1$ or $x_2$ can be freely chosen.

    Keep in mind we are interest only in the 'form' of the eigenvector, because an eigenvector of $A$ multiplied with a scalar is still an eigenvector of $A$.
    \begin{align*}
        0 & = (-1 + \sqrt{15})x + 7y     \\
        y & = \frac{(1 - \sqrt{15})x}{7}
    \end{align*}
    We can eliminate the fraction by setting  $x=7$.
    \begin{align*}
        x   & = 7                                          \\
        y   & = \frac{(1 - \sqrt{15})7}{7} = 1 - \sqrt{15} \\
        v_1 & = \begin{bmatrix}
            7 \\ 1 - \sqrt{15}
        \end{bmatrix}
    \end{align*}
    Same for $\lambda_2$:
    \begin{align*}
        \begin{bmatrix}
            3 - (4 + \sqrt{15}) & 7                   \\
            2                   & 5 - (4 - \sqrt{15})
        \end{bmatrix} \begin{bmatrix}
            x_1 \\ x_2
        \end{bmatrix} = \begin{bmatrix}
            0 \\ 0
        \end{bmatrix}
    \end{align*}
    \begin{align*}
        \begin{bmatrix}
            -1 - \sqrt{15} & 7             \\
            2              & 1 - \sqrt{15}
        \end{bmatrix} \begin{bmatrix}
            x_1 \\ x_2
        \end{bmatrix} = \begin{bmatrix}
            0 \\ 0
        \end{bmatrix}
    \end{align*}
    We can eliminate the II row by subtracting I $ \left( \frac{2}{-1 - \sqrt{15}} \right) $ \\
    \begin{align*}
        \begin{bmatrix}
            -1  - \sqrt{15} & 7 \\
            0               & 0
        \end{bmatrix} \begin{bmatrix}
            x_1 \\ x_2
        \end{bmatrix} = \begin{bmatrix}
            0 \\ 0
        \end{bmatrix} \\
    \end{align*}
    Solving for $x_1$, $x_2$:
    \begin{align*}
        (-1-\sqrt{15}) x_1 + 7 x_2 & = 0                           \\
        x_2                        & = \frac{1 + \sqrt{15}x_1}{7}  \\
        x_1                        & = 7  \text{ (chosen)}         \\
        x_2                        & = 1 + \sqrt{15}               \\
        v_2                        & = \begin{bmatrix}
            7 \\ 1 + \sqrt{15}
        \end{bmatrix}
    \end{align*}
\end{example}
\begin{matlab}
    \apilink{eig}{https://www.mathworks.com/help/matlab/ref/eig.html}
    \begin{lstlisting}
        >> [a, d] = eig([3, 7; 11, 3])
    a =
        0.6236   -0.6236
        0.7817    0.7817
    d =
        11.7750         0
        0   -5.7750
    \end{lstlisting}
\end{matlab}
\subsubsection{Geometric multiplicity}
The geometry multiplicity \(\gamma_A \) of an eigenvector is the dimension of the associatited eigenspace.


The geometry multiplicity of an eigenvector can't be largert than the arithmetic multiplicity.
\begin{equation}
    \gamma_A(\lambda_i) \leq \mu_a(\lambda_1)
\end{equation}
\begin{example}
    \begin{align*}
        A = \begin{bmatrix}
            2 & 0 & 0 & 0 \\ 0 & 0 & 0 &0 \\ 0 & 0 &0 &0 \\ 0 & 0 & 1 & 0
        \end{bmatrix}                                                  \\
        p_A(t) = t^3(t- 2)                                                               \\
        \lambda_1 = 2, \lambda_2 = 0                                                     \\
        \mu_A(2) = 1, \mu_A(0) = 3,                                                      \\
        \epsilon_1 = \span \{ \begin{bmatrix}
            2 \\ 0 \\ 0 \\ 0
        \end{bmatrix} \}                             \\
        \epsilon_2 = \span \{ \begin{bmatrix}
            0 \\ 1 \\ 0 \\ 0
        \end{bmatrix}, \begin{bmatrix}
            0 \\ 0 \\ 0 \\ 1
        \end{bmatrix}\} \\
        \gamma_a(2) = \dim \epsilon_1 = 1                                                \\
        \gamma_a(0) = \dim \epsilon_2 = 2
    \end{align*}
\end{example}
\subsection{Similarity}\label{similiarity}
Two square matrices $A$ and $B$ are similar when an if there exists an invertible $n \times n$ matrix U such that:
\begin{equation}
    A = U^{-1}BU
\end{equation}
It is denoted as
\begin{equation*}
    A \tilde{=} B
\end{equation*}
U is also called the change of base matrix.
Similar matrices have the same:
\begin{itemize}
    \item Characteristic polynomial
    \item Eigenvalues (but not eigenvectors)
    \item Determinant
    \item Trace
\end{itemize}
Similarity is an equivalence relation
\begin{itemize}
    \item A is similar to A
    \item If A is similar to B, then B is similar to A.
    \item If A is similar to B and B is similar to C, then A is similar to C.
\end{itemize}
\begin{example}
    \begin{align*}
        B = \begin{bmatrix}
            2 & 3 \\ 0 & 4
        \end{bmatrix}, A = \begin{bmatrix}
            3 & 4 \\ \frac{1}{4} & 3
        \end{bmatrix}, P = \begin{bmatrix}
            3 & 0 \\ 1 & 4
        \end{bmatrix}, P^{-1} = \begin{bmatrix}
            \frac{1}{3} & 0 \\ -\frac{1}{12} & \frac{1}{4}
        \end{bmatrix}
    \end{align*}
    \begin{align*}
        P^{-1}BP = \begin{bmatrix}
            \frac{1}{3} & 0 \\ -\frac{1}{12} & \frac{1}{4}
        \end{bmatrix}
        \begin{bmatrix}
            2 & 3 \\ 0 & 4
        \end{bmatrix}
        \begin{bmatrix}
            3 & 0 \\ 1 & 4
        \end{bmatrix} = \begin{bmatrix}
            \frac{2}{3} & 1 \\ -\frac{1}{6} & \frac{3}{4}
        \end{bmatrix}\begin{bmatrix}
            3 & 0 \\ 1 & 4
        \end{bmatrix} = \begin{bmatrix}
            3 & 4 \\ \frac{1}{4} & 3
        \end{bmatrix}
    \end{align*}
    \begin{align*}
        \det(B) & = 2 \cdot 4 - 3 \cdot 0 = 8                           \\
        \det(A) & = 3 \cdot 3 - 1 \cdot \frac{1}{4} = 8                 \\
        tr(A)   & = 3 + 3 = 6                                           \\
        tr(B)   & = 2 +4 = 6                                            \\
        p_B(t)  & = (2 - t)(4 - t) - 4 \cdot 0 = t^2 - 6t + 8           \\
        p_A(t)  & = (3 - t)(3 - t) - 4 \cdot \frac{1}{4} = t^2 - 6t + 8 \\
    \end{align*}
\end{example}
\section{Operations}
\subsection{Transposing}
Transpose of a matrix \(A\) is an operator which flips a matrix over its diagonal; that is, it switches the row and column indices of the matrix A by producing another matrix, often denoted by $A^T$.
\begin{example}
    \begin{align*}
        \begin{bmatrix}
            1 & 2 & 3
        \end{bmatrix}^T = \begin{bmatrix}
            1 \\
            2 \\
            3 \\
        \end{bmatrix}
    \end{align*}
\end{example}
\begin{example}
    \begin{align*}
        \begin{bmatrix}
            1 & 2 & 3 \\
            4 & 5 & 6 \\
            7 & 8 & 9 \\
        \end{bmatrix}^T = \begin{bmatrix}
            1 & 4 & 7 \\
            2 & 5 & 8 \\
            3 & 6 & 9 \\
        \end{bmatrix}
    \end{align*}
\end{example}
Notice the diagonal elements do not get swaped by transposing. So for any diagonal matrix D holds $D=D^T$.
\begin{matlab}
    \apilink{transpose}{https://www.mathworks.com/help/matlab/ref/transpose.html}
    \begin{lstlisting}
    A = [1,2,3;4,5,6]
    transpose(A)
    ans =
    1     4
    2     5
    3     6
    \end{lstlisting}
\end{matlab}
\subsubsection{Solving for eigenvalues and eigenvectors}
\begin{example}
    \begin{align*}
        A      & = \begin{bmatrix}
            3 & 7 \\ 2 & 5
        \end{bmatrix}                                                 \\                                                                                                                                                  \\
        p_A(t) & = \det(A - t I)  = \determinant{\begin{bmatrix}
                3 - t & 7 \\2  & 5 - t
            \end{bmatrix}} =  t^2 - 8 t + 1 \\
    \end{align*}
    We get the eigenvalues by setting \(p_A(\lambda) = 0\) and solving for \( \lambda \)
    \begin{align*}
        \lambda^2 - 8 \lambda + 1 = 0                                           \\
        \lambda_{12} = -\frac{-8}{2} \pm \sqrt{\left( \frac{-8}{2}\right)^2 -1} \\
        \lambda_1 = 4 - \sqrt{15},  \lambda_2 = 4 + \sqrt{15}                   \\
    \end{align*}
\end{example}
\subsection{Diagonalisation}
A matrix $A$ is diagonalizabe if $A$ is similar (see \ref{similiarity}) to a diagonal matrix $D$.
\begin{equation*}
    A = U^{-1}DU
\end{equation*}
\subsubsection{Eigenbase}
A  matrix can be diagonalized using its eigenvalues and eigenvectors.
D is a diagonal matrix containing the eigenvalues $\lambda_i$ on it main diagonal:
The the bases eigenspaces $\epsilon_i$ form a base called \textbf{eigenbase} (when the arithmetic multiplicity of an eigenvalue is 1 then $\epsilon$ is just the eigenvector).
So change of base matrix $U$ has the base vectors of the eigenspaces as it's columns.
\begin{equation}
    U = \begin{bmatrix}
        \epsilon_1(\lambda_1) & \epsilon_2(\lambda_2) & \dots & \epsilon_i(\lambda_i)
    \end{bmatrix}
\end{equation}